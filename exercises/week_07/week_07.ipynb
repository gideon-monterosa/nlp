{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from datasets import load_dataset\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "random.seed(42)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T21:51:54.465608Z",
     "start_time": "2025-05-25T21:51:46.899897Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 07\n",
    "\n",
    "- Exercise 1: Read chapter *1.4 Applying BERT Models* in \n",
    "[Foundations of Large Language Models](https://arxiv.org/abs/2501.09223). How can you use a pre-trained BERT model for:\n",
    "\n",
    "    - Text classification?\n",
    "    - Named entity recognition?\n",
    "    - Question answering?\n",
    "    - Sequence Labeling? POS, NER?\n",
    "    - Span-Prediction? Make an example of a span-prediction task.\n",
    "    - What is catastrophic forgetting and how can it be \"avoided\"?\n",
    "- Exercise 2: Go through the [Hugging Face tutorial](https://huggingface.co/blog/sentiment-analysis-python) on sequence classification and choose your own model from the link in the tutorial [here](https://huggingface.co/models?pipeline_tag=text-classification&sort=downloads&search=sentiment). Import the `movies` data, choose a pretrained model and try to do a prediction. Can you also finetune the your model? Does it get better?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 1\n",
    "\n",
    "**Text classification?**\n",
    "\n",
    "Man fügt eine Klassifikationsschicht auf den [CLS] Token von BERT hinzu und trainiert diese für die spezifische Anzahl von Klassen.\n",
    "\n",
    "**Named entity recognition?**\n",
    "\n",
    "Man verwendet BERT mit einer Token-Klassifikationsschicht, die jedem Token im Text ein Label (z.B. B-PER, I-PER, O) zuweist.\n",
    "\n",
    "**Question answering?**\n",
    "\n",
    "BERT wird mit zwei Ausgabeköpfen versehen, die die Start- und Endposition der Antwort im gegebenen Kontext vorhersagen.\n",
    "\n",
    "**Sequence Labeling? POS, NER?**\n",
    "\n",
    "Man nutzt BERT's Token-Repräsentationen und fügt eine Klassifikationsschicht hinzu, die jedem Token ein Label aus einem vordefinierten Tagset zuweist.\n",
    "\n",
    "**Span-Prediction? Make an example of a span-prediction task.**\n",
    "\n",
    "Span-Prediction identifiziert zusammenhängende Textabschnitte (Spans) für Aufgaben wie Coreference Resolution, wo z.B. \"John\" und \"he\" als referenzgleiche Spans erkannt werden.\n",
    "\n",
    "**What is catastrophic forgetting and how can it be \"avoided\"?**\n",
    "\n",
    "Catastrophic Forgetting ist das Phänomen, dass ein Modell beim Training auf neue Aufgaben das Wissen aus vorherigen Aufgaben verliert - vermieden wird es durch Techniken wie niedrige Lernraten, Adapter-Module oder Elastic Weight Consolidation.\n",
    "\n",
    "## Exercise 2\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade IMDB Movie Reviews Datensatz...\n",
      "Anzahl Trainingsbeispiele: 25000\n",
      "Anzahl Testbeispiele: 25000\n",
      "\n",
      "Beispiel aus dem Datensatz:\n",
      "Text: I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ev...\n",
      "Label: 0 (0=negativ, 1=positiv)\n"
     ]
    }
   ],
   "source": [
    "print(\"Lade IMDB Movie Reviews Datensatz...\")\n",
    "imdb_dataset = load_dataset(\"imdb\")\n",
    "print(f\"Anzahl Trainingsbeispiele: {len(imdb_dataset['train'])}\")\n",
    "print(f\"Anzahl Testbeispiele: {len(imdb_dataset['test'])}\")\n",
    "\n",
    "print(\"\\nBeispiel aus dem Datensatz:\")\n",
    "print(f\"Text: {imdb_dataset['train'][0]['text'][:200]}...\")\n",
    "print(f\"Label: {imdb_dataset['train'][0]['label']} (0=negativ, 1=positiv)\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T21:51:59.207107Z",
     "start_time": "2025-05-25T21:51:54.467738Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verwende Modell: distilbert-base-uncased-finetuned-sst-2-english\n",
      "\n",
      "--- Vorhersagen mit dem vortrainierten Modell ---\n",
      "\n",
      "Text: This movie was absolutely fantastic! I loved every minute of it.\n",
      "Vorhersage: POSITIVE (Konfidenz: 0.9999)\n",
      "\n",
      "Text: Terrible film. Complete waste of time.\n",
      "Vorhersage: NEGATIVE (Konfidenz: 0.9998)\n",
      "\n",
      "Text: The movie was okay, nothing special but not bad either.\n",
      "Vorhersage: POSITIVE (Konfidenz: 0.8738)\n",
      "\n",
      "Text: Best movie I've seen all year! Highly recommend!\n",
      "Vorhersage: POSITIVE (Konfidenz: 0.9999)\n",
      "\n",
      "Text: Boring and predictable. Would not watch again.\n",
      "Vorhersage: NEGATIVE (Konfidenz: 0.9995)\n"
     ]
    }
   ],
   "source": [
    "model_options = {\n",
    "    \"distilbert\": \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    \"roberta\": \"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "    \"bert\": \"nlptown/bert-base-multilingual-uncased-sentiment\",\n",
    "    \"xlm-roberta\": \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "}\n",
    "\n",
    "selected_model = model_options[\"distilbert\"]\n",
    "print(f\"\\nVerwende Modell: {selected_model}\")\n",
    "\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=selected_model)\n",
    "\n",
    "test_texts = [\n",
    "    \"This movie was absolutely fantastic! I loved every minute of it.\",\n",
    "    \"Terrible film. Complete waste of time.\",\n",
    "    \"The movie was okay, nothing special but not bad either.\",\n",
    "    \"Best movie I've seen all year! Highly recommend!\",\n",
    "    \"Boring and predictable. Would not watch again.\"\n",
    "]\n",
    "\n",
    "print(\"\\n--- Vorhersagen mit dem vortrainierten Modell ---\")\n",
    "for text in test_texts:\n",
    "    result = sentiment_pipeline(text[:512])\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"Vorhersage: {result[0]['label']} (Konfidenz: {result[0]['score']:.4f})\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T21:52:01.565037Z",
     "start_time": "2025-05-25T21:51:59.209268Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation auf IMDB Testdaten ---\n",
      "Label-Verteilung im Test-Sample:\n",
      "Negative (0): 53\n",
      "Positive (1): 47\n",
      "\n",
      "Vorhersage-Verteilung:\n",
      "Negative (0): 52\n",
      "Positive (1): 48\n",
      "\n",
      "Genauigkeit: 0.8300\n",
      "Präzision: 0.8125\n",
      "Recall: 0.8298\n",
      "F1-Score: 0.8211\n"
     ]
    }
   ],
   "source": [
    "def evaluate_imdb(pipeline):\n",
    "    print(\"\\n--- Evaluation auf IMDB Testdaten ---\")\n",
    "    shuffled_test = imdb_dataset['test'].shuffle(seed=42)\n",
    "    test_sample = shuffled_test.select(range(100))\n",
    "    test_texts_sample = test_sample['text']\n",
    "    test_labels_sample = test_sample['label']\n",
    "\n",
    "    print(f\"Label-Verteilung im Test-Sample:\")\n",
    "    print(f\"Negative (0): {sum(1 for l in test_labels_sample if l == 0)}\")\n",
    "    print(f\"Positive (1): {sum(1 for l in test_labels_sample if l == 1)}\")\n",
    "\n",
    "    predictions = []\n",
    "    for i, text in enumerate(test_texts_sample):\n",
    "        try:\n",
    "            result = pipeline(text[:512])[0]\n",
    "            pred_label = 1 if result['label'] == 'POSITIVE' else 0\n",
    "            predictions.append(pred_label)\n",
    "        except:\n",
    "            predictions.append(0)\n",
    "\n",
    "    print(f\"\\nVorhersage-Verteilung:\")\n",
    "    print(f\"Negative (0): {sum(1 for p in predictions if p == 0)}\")\n",
    "    print(f\"Positive (1): {sum(1 for p in predictions if p == 1)}\")\n",
    "\n",
    "    accuracy = accuracy_score(test_labels_sample, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(test_labels_sample, predictions, average='binary')\n",
    "\n",
    "    print(f\"\\nGenauigkeit: {accuracy:.4f}\")\n",
    "    print(f\"Präzision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    \n",
    "evaluate_imdb(sentiment_pipeline)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T21:52:06.999484Z",
     "start_time": "2025-05-25T21:52:01.567344Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a4d4c62631834502bf8617a75a1aaa78"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/200 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "988894590a254ca89e5233b6816ff801"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starte Finetuning...\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [250/250 05:07, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.374533</td>\n      <td>0.895000</td>\n      <td>0.886486</td>\n      <td>0.921348</td>\n      <td>0.854167</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.462950</td>\n      <td>0.895000</td>\n      <td>0.890052</td>\n      <td>0.894737</td>\n      <td>0.885417</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation nach Finetuning ---\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [25/25 00:08]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Results: {'eval_loss': 0.3745329678058624, 'eval_accuracy': 0.895, 'eval_f1': 0.8864864864864865, 'eval_precision': 0.9213483146067416, 'eval_recall': 0.8541666666666666, 'eval_runtime': 8.5284, 'eval_samples_per_second': 23.451, 'eval_steps_per_second': 2.931, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(selected_model)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(selected_model)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "small_train_dataset = imdb_dataset['train'].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = imdb_dataset['test'].shuffle(seed=42).select(range(200))\n",
    "\n",
    "tokenized_train = small_train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval = small_eval_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"\\nStarte Finetuning...\")\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\n--- Evaluation nach Finetuning ---\")\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Eval Results: {eval_results}\")\n",
    "\n",
    "trainer.save_model(\"./finetuned_model\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T21:57:29.574492Z",
     "start_time": "2025-05-25T21:52:07.002764Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Vorhersagen ohne finetuning ---\n",
      "\n",
      "--- Evaluation auf IMDB Testdaten ---\n",
      "Label-Verteilung im Test-Sample:\n",
      "Negative (0): 53\n",
      "Positive (1): 47\n",
      "\n",
      "Vorhersage-Verteilung:\n",
      "Negative (0): 52\n",
      "Positive (1): 48\n",
      "\n",
      "Genauigkeit: 0.8300\n",
      "Präzision: 0.8125\n",
      "Recall: 0.8298\n",
      "F1-Score: 0.8211\n",
      "\n",
      "--- Vorhersagen mit dem finetuned Modell ---\n",
      "\n",
      "--- Evaluation auf IMDB Testdaten ---\n",
      "Label-Verteilung im Test-Sample:\n",
      "Negative (0): 53\n",
      "Positive (1): 47\n",
      "\n",
      "Vorhersage-Verteilung:\n",
      "Negative (0): 53\n",
      "Positive (1): 47\n",
      "\n",
      "Genauigkeit: 0.8600\n",
      "Präzision: 0.8511\n",
      "Recall: 0.8511\n",
      "F1-Score: 0.8511\n"
     ]
    }
   ],
   "source": [
    "finetuned_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"./finetuned_model\",\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(\"\\n--- Vorhersagen ohne finetuning ---\")\n",
    "evaluate_imdb(sentiment_pipeline)\n",
    "\n",
    "print(\"\\n--- Vorhersagen mit dem finetuned Modell ---\")\n",
    "evaluate_imdb(finetuned_pipeline)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T21:58:49.891876Z",
     "start_time": "2025-05-25T21:58:39.827717Z"
    }
   },
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-nlp-exercises",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
